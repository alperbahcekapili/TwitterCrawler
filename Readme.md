
# Prerequisites

* Python3 and Redis server needs to be installed
        For needed packages please refer to requirements.txt

* Please write your Twitter API secrets to a file named "secrets.json" that is located under "TwitterCrawler" folder
The structure of the secret file is as follows: 

        {
        "consumer_key": "<consumer_key>",
        "consumer_secret": "<consumer_secret>",
        "access_token": "<access_token>",
        "access_token_secret": "<access_token_secret>"
        }



# Instructions


## Crawler

You can crawl tweets based on topics. For example you can crawl the tweets about "e-sports" with providing keywords: 

```
["LOL", "CSGO", "WoW", "Witcher", ...]
```


To make this happen you should provide a topics.json file. The content of this file should be: 
```
[
    {
        "name":"e-sports",
        "keywords":["LOL", "CSGO", "WoW", "Witcher"],
        "lang":"tr"
    },
    {
        <another topic>
    }
]
```


## NLP Models

We will integrate NLP models for use 

## Preprocess


You can preprocess the tweet you downloaded. You need to upload these tweets as bulk files. Here you will recieve visualizations of the statistics about tweets.


Here we extract a couple necessary fields for our work. You can change the code to match your purpose as well


Preprocessed tweets will be saved as csv' s. So we suggest you to ensure you have sufficent storage before beginning of the preproceess.


## Stance Detection

Please give a file that has the following form: (stance names should not contain '/')

```
{stance}
{twitter_profile}
{twitter_profile}
{twitter_profile}
```

What we do here is retweet based stance detection. You can find more about from here: https://ieeexplore.ieee.org/abstract/document/9789178


We found that informative twitter profiles have huge impact on accuracy of this stage. So we suggest you to be generous providing number of profiles.


## User Based Dashboard

For both dump and processed versions of data, you can have a user based dashboard here. More visualizations will be implemented...

For gender detection there is a file needed which is called names.csv under local folder. This file should be csv. It should contain names in its first column and should contain "M" or "F" with respect to names gender. M is identifier for male and F female.

## Location Detection

Here we parse all data and store users that has the locations we desire. For this part you need to provide a file that has the following structure:


```
<base location>:[<possible abbreviation>,<possible abbreviation>,<possible abbreviation> ]
<base location>:[<possible abbreviation>,<possible abbreviation>,<possible abbreviation> ]
<base location>:[<possible abbreviation>,<possible abbreviation>,<possible abbreviation> ]
```

Ä°f a users location is in possible abbr. or this possible abbr. in users location, this users location will be replaced with base location.


## Location Based Stance Deteciton

Simply counting users that are labeled by retweet based stance detections is not very accurate path. It has various reasons, you can find more about in this paper: https://ieeexplore.ieee.org/abstract/document/9789178 

This method is explained better in paper but to summarize: We create support ratios based on both locaitons of users and expected users from this location. With this way we can more accurate results.


In this page there are lots of inputs. Let's go one by one:

1) Electorants file: 

This file is a csv. That has the following format: 

```
Year,<Loc1>,<Loc2>,<Loc3>
2021-01-01,<#elecs>,<#elecs>,<#elecs>
2022-01-01,<#elecs>,<#elecs>,<#elecs>
```

2) User Location File: 

This file should be generated by location detecion process


3) User Stance File: 

This file should be generated by stance detecion process


4) User-id Fictionary File: 

This is a json file that has the username-id pairs. You should generate this file with the python script that is located under preprocess scripts. This process will be added as a page in future for easier usage.


